"""
A Flask-based chatbot application powered by the OpenAI API.
This file receives user input via HTTP requests and returns generated responses.
This is intended for deployment on Render.
"""

import os  # For interacting with environment variables
from flask import Flask, request, jsonify, render_template_string  # Flask modules for web server and HTTP handling
import openai  # OpenAI API client for generating responses  

# Create a Flask application instance
app = Flask(__name__)

# Retrieve and set the OpenAI API key securely from an environment variable
openai.api_key = os.environ.get("OPENAI_API_KEY")
if openai.api_key is None:
    raise ValueError("The OPENAI_API_KEY environment variable is not set. Please define it for the OpenAI API access.")

# Define a simple HTML form template for manual testing
html_form = """
<!doctype html>
<html>
<head>
    <title>Chatbot</title>
</head>
<body>
    <h1>Chat with Bot</h1>
    <form action="/chat" method="post">
        <label for="message">Your Message:</label><br>
        <textarea id="message" name="message" rows="4" cols="50" placeholder="Enter your message here..."></textarea><br>
        <input type="submit" value="Send">
    </form>
</body>
</html>
"""

@app.route("/", methods=["GET"])
def home():
    """
    Home route that returns a simple HTML form to interact with the chatbot.
    This is useful for quick manual testing of the chatbot directly in the browser.
    """
    return render_template_string(html_form)

@app.route("/chat", methods=["POST"])
def chat():
    """
    The /chat endpoint receives user input and returns a response generated by OpenAI.
    It supports both form data submissions and JSON payloads.
    """
    # Check if the incoming request is in JSON format.
    if request.is_json:
        data = request.get_json()
        user_message = data.get("message")
    else:
        user_message = request.form.get("message")
    
    # Validate the user input to ensure it's not empty
    if not user_message or user_message.strip() == "":
        return jsonify({"error": "Please provide a valid message."}), 400
    
    try:
        # Use the OpenAI ChatCompletion API to generate a chatbot response.
        # We're using the gpt-3.5-turbo model here.
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # Specify the model to use
            messages=[
                {"role": "user", "content": user_message}  # Provide the user's message as input
            ],
            max_tokens=150  # Limit the number of tokens in the response to avoid overly long outputs
        )
        
        # Extract the chatbot's reply from the API response
        chatbot_reply = response.choices[0].message['content'].strip()
        
        # Return the chatbot's reply as a JSON response
        return jsonify({"reply": chatbot_reply})
    except Exception as e:
        # In case of an error, return a JSON response with the error message and a 500 status code
        return jsonify({"error": str(e)}), 500

# Main entry point - if this script is executed directly, start the Flask application
if __name__ == "__main__":
    # app.run() starts the Flask development server.
    # host='0.0.0.0' allows the server to be accessible externally, and the port is read from the PORT environment variable if available.
    app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 5000)), debug=True)